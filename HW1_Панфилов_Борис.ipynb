{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcecc5b",
   "metadata": {},
   "source": [
    "### Часть 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!sudo apt install unzip\n",
    "!sudo apt-get install p7zip-full\n",
    "\n",
    "!export KAGGLE_USERNAME='borispanfilov'\n",
    "!export KAGGLE_KEY='23e1a26705b833184e1835da72c45fe3'\n",
    "\n",
    "!kaggle competitions download -c avito-context-ad-clicks\n",
    "!unzip avito-context-ad-clicks.zip\n",
    "!7z x VisitsStream.tsv.7z\n",
    "\n",
    "!head -n 1000000 VisitsStream.tsv > VisitsStream_1M.tsv\n",
    "!cut -f1 VisitsStream_1M.tsv | sort | uniq -c | sort -nr | head -10 | awk '{printf \"%8d %s\\n\", $1, $2}' > top_users.txt\n",
    "!hdfs dfs -put -f top_users.txt s3a://avito-top-users/top_users.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5a179",
   "metadata": {},
   "source": [
    "ссылка на выгруженный файл: https://storage.yandexcloud.net/bspanfilov-lsml/top_users.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbaf242",
   "metadata": {},
   "source": [
    "### Часть 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d6e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "!7z x AdsInfo.tsv.7z\n",
    "! sed -i -e '1'd AdsInfo.tsv\n",
    "! head -n 2 AdsInfo.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b59f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir -p user/input/ads\n",
    "!hdfs dfs -put AdsInfo.tsv /user/input/ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3fa817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CategoryPriceCount.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile CategoryPriceCount.py\n",
    "import sys\n",
    "\n",
    "def _rewind_stream(stream):\n",
    "    for _ in stream:\n",
    "        pass\n",
    "\n",
    "def mapper():\n",
    "    for line in sys.stdin:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 5:\n",
    "            category_id = parts[2]\n",
    "            price = parts[4]\n",
    "            if category_id != 'NULL' and price != 'NULL' and price.isdigit():\n",
    "                print(f\"{category_id}\\t{price}\")\n",
    "                \n",
    "def reducer():\n",
    "    current_category = None\n",
    "    total = 0\n",
    "\n",
    "    for line in sys.stdin:\n",
    "        line = line.strip()\n",
    "        category, price = line.split('\\t')\n",
    "        price = float(price)\n",
    "\n",
    "        if current_category == category:\n",
    "            total += price\n",
    "        else:\n",
    "            if current_category is not None:\n",
    "                print(f\"{current_category}\\t{total}\")\n",
    "            current_category = category\n",
    "            total = price\n",
    "\n",
    "    if current_category is not None:\n",
    "        print(f\"{current_category}\\t{total}\")\n",
    "    _rewind_stream(sys.stdin)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    mr_command = sys.argv[1]\n",
    "    {\n",
    "        'map': mapper,\n",
    "        'reduce': reducer\n",
    "    }[mr_command]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c053c653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /user/output/ads\n",
      "packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-3.2.2.jar] /tmp/streamjob3770900210737314981.jar tmpDir=null\n",
      "2025-02-10 06:41:27,927 INFO client.RMProxy: Connecting to ResourceManager at rc1a-dataproc-m-88s08077gbn3tl4n.mdb.yandexcloud.net/10.128.0.14:8032\n",
      "2025-02-10 06:41:28,091 INFO client.AHSProxy: Connecting to Application History server at rc1a-dataproc-m-88s08077gbn3tl4n.mdb.yandexcloud.net/10.128.0.14:10200\n",
      "2025-02-10 06:41:28,125 INFO client.RMProxy: Connecting to ResourceManager at rc1a-dataproc-m-88s08077gbn3tl4n.mdb.yandexcloud.net/10.128.0.14:8032\n",
      "2025-02-10 06:41:28,125 INFO client.AHSProxy: Connecting to Application History server at rc1a-dataproc-m-88s08077gbn3tl4n.mdb.yandexcloud.net/10.128.0.14:10200\n",
      "2025-02-10 06:41:28,340 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1739169572115_0001\n",
      "2025-02-10 06:41:29,062 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2025-02-10 06:41:29,083 INFO net.NetworkTopology: Adding a new node: /default-rack/10.128.0.26:9866\n",
      "2025-02-10 06:41:29,086 INFO net.NetworkTopology: Adding a new node: /default-rack/10.128.0.21:9866\n",
      "2025-02-10 06:41:29,192 INFO mapreduce.JobSubmitter: number of splits:20\n",
      "2025-02-10 06:41:29,485 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1739169572115_0001\n",
      "2025-02-10 06:41:29,487 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2025-02-10 06:41:29,710 INFO conf.Configuration: resource-types.xml not found\n",
      "2025-02-10 06:41:29,710 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2025-02-10 06:41:30,161 INFO impl.YarnClientImpl: Submitted application application_1739169572115_0001\n",
      "2025-02-10 06:41:30,204 INFO mapreduce.Job: The url to track the job: http://rc1a-dataproc-m-88s08077gbn3tl4n.mdb.yandexcloud.net:8088/proxy/application_1739169572115_0001/\n",
      "2025-02-10 06:41:30,206 INFO mapreduce.Job: Running job: job_1739169572115_0001\n",
      "2025-02-10 06:41:38,309 INFO mapreduce.Job: Job job_1739169572115_0001 running in uber mode : false\n",
      "2025-02-10 06:41:38,310 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2025-02-10 06:41:56,424 INFO mapreduce.Job:  map 7% reduce 0%\n",
      "2025-02-10 06:41:58,434 INFO mapreduce.Job:  map 18% reduce 0%\n",
      "2025-02-10 06:42:02,457 INFO mapreduce.Job:  map 21% reduce 0%\n",
      "2025-02-10 06:42:03,470 INFO mapreduce.Job:  map 24% reduce 0%\n",
      "2025-02-10 06:42:04,475 INFO mapreduce.Job:  map 33% reduce 0%\n",
      "2025-02-10 06:42:05,480 INFO mapreduce.Job:  map 35% reduce 0%\n",
      "2025-02-10 06:42:19,546 INFO mapreduce.Job:  map 37% reduce 0%\n",
      "2025-02-10 06:42:20,550 INFO mapreduce.Job:  map 49% reduce 0%\n",
      "2025-02-10 06:42:21,555 INFO mapreduce.Job:  map 52% reduce 0%\n",
      "2025-02-10 06:42:25,572 INFO mapreduce.Job:  map 53% reduce 0%\n",
      "2025-02-10 06:42:26,577 INFO mapreduce.Job:  map 59% reduce 0%\n",
      "2025-02-10 06:42:27,581 INFO mapreduce.Job:  map 64% reduce 0%\n",
      "2025-02-10 06:42:28,585 INFO mapreduce.Job:  map 66% reduce 0%\n",
      "2025-02-10 06:42:30,595 INFO mapreduce.Job:  map 68% reduce 0%\n",
      "2025-02-10 06:42:31,600 INFO mapreduce.Job:  map 70% reduce 0%\n",
      "2025-02-10 06:42:42,651 INFO mapreduce.Job:  map 76% reduce 23%\n",
      "2025-02-10 06:42:43,655 INFO mapreduce.Job:  map 78% reduce 23%\n",
      "2025-02-10 06:42:46,670 INFO mapreduce.Job:  map 89% reduce 23%\n",
      "2025-02-10 06:42:48,679 INFO mapreduce.Job:  map 89% reduce 27%\n",
      "2025-02-10 06:42:49,682 INFO mapreduce.Job:  map 90% reduce 27%\n",
      "2025-02-10 06:42:52,696 INFO mapreduce.Job:  map 93% reduce 27%\n",
      "2025-02-10 06:42:54,704 INFO mapreduce.Job:  map 95% reduce 27%\n",
      "2025-02-10 06:42:55,709 INFO mapreduce.Job:  map 100% reduce 27%\n",
      "2025-02-10 06:43:00,727 INFO mapreduce.Job:  map 100% reduce 38%\n",
      "2025-02-10 06:43:06,751 INFO mapreduce.Job:  map 100% reduce 46%\n",
      "2025-02-10 06:43:12,774 INFO mapreduce.Job:  map 100% reduce 54%\n",
      "2025-02-10 06:43:18,795 INFO mapreduce.Job:  map 100% reduce 62%\n",
      "2025-02-10 06:43:24,817 INFO mapreduce.Job:  map 100% reduce 74%\n",
      "2025-02-10 06:43:30,838 INFO mapreduce.Job:  map 100% reduce 87%\n",
      "2025-02-10 06:43:35,856 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2025-02-10 06:43:36,866 INFO mapreduce.Job: Job job_1739169572115_0001 completed successfully\n",
      "2025-02-10 06:43:36,946 INFO mapreduce.Job: Counters: 56\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=64784044\n",
      "\t\tFILE: Number of bytes written=134973073\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5352038746\n",
      "\t\tHDFS: Number of bytes written=964\n",
      "\t\tHDFS: Number of read operations=65\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=3\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=21\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=19\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=1398780\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=205650\n",
      "\t\tTotal time spent by all map tasks (ms)=466260\n",
      "\t\tTotal time spent by all reduce tasks (ms)=68550\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=466260\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=68550\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=1432350720\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=210585600\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=36893298\n",
      "\t\tMap output records=36742997\n",
      "\t\tMap output bytes=306054381\n",
      "\t\tMap output materialized bytes=65102832\n",
      "\t\tInput split bytes=2760\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=52\n",
      "\t\tReduce shuffle bytes=65102832\n",
      "\t\tReduce input records=36742997\n",
      "\t\tReduce output records=52\n",
      "\t\tSpilled Records=73485994\n",
      "\t\tShuffled Maps =20\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=20\n",
      "\t\tGC time elapsed (ms)=3226\n",
      "\t\tCPU time spent (ms)=242450\n",
      "\t\tPhysical memory (bytes) snapshot=8272392192\n",
      "\t\tVirtual memory (bytes) snapshot=91118104576\n",
      "\t\tTotal committed heap usage (bytes)=9272557568\n",
      "\t\tPeak Map Physical memory (bytes)=426311680\n",
      "\t\tPeak Map Virtual memory (bytes)=4359811072\n",
      "\t\tPeak Reduce Physical memory (bytes)=761630720\n",
      "\t\tPeak Reduce Virtual memory (bytes)=4361011200\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=5352035986\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=964\n",
      "2025-02-10 06:43:36,946 INFO streaming.StreamJob: Output directory: /user/output/ads\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r /user/output/ads || true\n",
    "! yarn jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
    "    -D mapreduce.job.name=\"CategoryPriceCount\" \\\n",
    "    -D mapreduce.job.reduces=1 \\\n",
    "    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator \\\n",
    "    -D mapreduce.partition.keycomparator.options=\"-k1,1 -n\" \\\n",
    "    -D mapreduce.map.output.key.field.separator='\\t' \\\n",
    "    -files CategoryPriceCount.py \\\n",
    "    -mapper \"python3 CategoryPriceCount.py map\" \\\n",
    "    -reducer \"python3 CategoryPriceCount.py reduce\" \\\n",
    "    -input /user/input/ads \\\n",
    "    -output /user/output/ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d863c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 ubuntu hadoop          0 2025-02-10 06:43 /user/output/ads/_SUCCESS\r\n",
      "-rw-r--r--   1 ubuntu hadoop        964 2025-02-10 06:43 /user/output/ads/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/output/ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54cdab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t270740247372.0\r\n",
      "3\t269719275202.0\r\n",
      "4\t386615276678.0\r\n",
      "5\t194378853180.0\r\n",
      "6\t1081387755737.0\r\n",
      "8\t72750.0\r\n",
      "9\t368983032949.0\r\n",
      "10\t778047753029.0\r\n",
      "11\t286397794715.0\r\n",
      "13\t360294036962.0\r\n",
      "14\t1818747309298.0\r\n",
      "15\t1175981626.0\r\n",
      "16\t4898855593.0\r\n",
      "18\t1189957510095.0\r\n",
      "19\t1225981598150.0\r\n",
      "20\t1112546355170.0\r\n",
      "22\t3615683686904.0\r\n",
      "23\t438290250010.0\r\n",
      "25\t510975326382.0\r\n",
      "26\t1516170218902.0\r\n",
      "27\t752807821253.0\r\n",
      "29\t103222877542.0\r\n",
      "30\t956113114474.0\r\n",
      "31\t4055085405969.0\r\n",
      "32\t19513368275737.0\r\n",
      "33\t10701372760148.0\r\n",
      "34\t6296233036403.0\r\n",
      "35\t134053168200.0\r\n",
      "36\t179741332416.0\r\n",
      "37\t2833544249369.0\r\n",
      "38\t1911845488400.0\r\n",
      "41\t8331383550142.0\r\n",
      "42\t9846683556066.0\r\n",
      "43\t8988120021083.0\r\n",
      "44\t93567453953.0\r\n",
      "45\t1873728809331.0\r\n",
      "46\t219880267974.0\r\n",
      "47\t1143968570527.0\r\n",
      "48\t1040727706890.0\r\n",
      "50\t5021543119173.0\r\n",
      "51\t588637293.0\r\n",
      "52\t862360905.0\r\n",
      "53\t1305060032868.0\r\n",
      "54\t13857529612184.0\r\n",
      "57\t537704430655.0\r\n",
      "59\t742623523685.0\r\n",
      "60\t1277750145478.0\r\n",
      "250001\t3880374977875.0\r\n",
      "250004\t14254404906260.0\r\n",
      "250005\t17795315492793.0\r\n",
      "250006\t8753614085158.0\r\n",
      "500001\t1799885981114.0\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/output/ads/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b5f6789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 06:56:41,260 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2025-02-10 06:56:41,332 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2025-02-10 06:56:41,332 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\n",
      "2025-02-10 06:56:43,038 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\n",
      "2025-02-10 06:56:43,038 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\n",
      "2025-02-10 06:56:43,038 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -get /user/output/ads/part-00000 part-00000\n",
    "!hdfs dfs -put -f part-00000 s3a://bspanfilov-lsml/CategoryPriceCount.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454a1c4",
   "metadata": {},
   "source": [
    "ссылка на результат: https://storage.yandexcloud.net/bspanfilov-lsml/CategoryPriceCount.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
